{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Analysis with PELT and HDBSCAN\n",
    "\n",
    "This notebook provides an interactive environment for analyzing signals using:\n",
    "1. **PELT (Pruned Exact Linear Time)** for change point detection\n",
    "2. **HDBSCAN** for clustering and smoothing the detected transitions\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.5' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import hdbscan\n",
    "import ruptures as rpt\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Import our custom modules\n",
    "from lib.db_connection import DatabaseConnection\n",
    "from lib.signal_utils import SignalProcessor\n",
    "from lib.visualization import SignalVisualizer\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Initialize database connection\n",
    "db = DatabaseConnection()\n",
    "print(\"✅ Environment loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Analysis Parameters\n",
    "\n",
    "Use the widgets below to select:\n",
    "- Signal type to analyze\n",
    "- Date range for analysis\n",
    "- PELT and HDBSCAN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available signals\n",
    "signal_configs = db.get_signal_configs()\n",
    "signal_options = [(f\"{row['display_name']} ({row['signal_name']})\", row['signal_name']) \n",
    "                  for _, row in signal_configs.iterrows()]\n",
    "\n",
    "# Create widgets\n",
    "signal_dropdown = widgets.Dropdown(\n",
    "    options=signal_options,\n",
    "    value=signal_options[0][1] if signal_options else None,\n",
    "    description='Signal:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "date_picker = widgets.DatePicker(\n",
    "    description='Analysis Date:',\n",
    "    value=date.today() - timedelta(days=1),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# PELT parameters\n",
    "pelt_penalty = widgets.FloatSlider(\n",
    "    value=1.0,\n",
    "    min=0.1,\n",
    "    max=5.0,\n",
    "    step=0.1,\n",
    "    description='PELT Penalty:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "min_segment_size = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=2,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Min Segment Size:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# HDBSCAN parameters\n",
    "min_cluster_size = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=2,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Min Cluster Size:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "epsilon = widgets.FloatSlider(\n",
    "    value=1800.0,  # 30 minutes in seconds\n",
    "    min=300.0,\n",
    "    max=7200.0,\n",
    "    step=300.0,\n",
    "    description='Epsilon (seconds):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Display widgets\n",
    "display(HTML(\"<h3>Signal Selection</h3>\"))\n",
    "display(signal_dropdown, date_picker)\n",
    "\n",
    "display(HTML(\"<h3>PELT Parameters</h3>\"))\n",
    "display(pelt_penalty, min_segment_size)\n",
    "\n",
    "display(HTML(\"<h3>HDBSCAN Parameters</h3>\"))\n",
    "display(min_cluster_size, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Data Retrieval and Visualization\n",
    "\n",
    "Fetch signal data from the database and visualize raw data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected parameters\n",
    "selected_signal = signal_dropdown.value\n",
    "selected_date = date_picker.value\n",
    "\n",
    "# Get signal configuration\n",
    "signal_config = signal_configs[signal_configs['signal_name'] == selected_signal].iloc[0]\n",
    "\n",
    "print(f\"📊 Analyzing: {signal_config['display_name']}\")\n",
    "print(f\"📅 Date: {selected_date}\")\n",
    "print(f\"📝 Description: {signal_config['description']}\")\n",
    "print(f\"📏 Unit: {signal_config['unit']}\")\n",
    "print(f\"🏗️ Archetype: {signal_config['archetype']}\")\n",
    "\n",
    "# Fetch data\n",
    "df = db.get_signals_for_date_range(\n",
    "    signal_name=selected_signal,\n",
    "    start_date=selected_date,\n",
    "    end_date=selected_date\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 Found {len(df)} signals for {selected_date}\")\n",
    "\n",
    "if not df.empty:\n",
    "    # Show data sample\n",
    "    print(\"\\n🔍 Data Sample:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    # Plot raw signals\n",
    "    fig = SignalVisualizer.plot_raw_signals(\n",
    "        df, \n",
    "        signal_config['display_name'],\n",
    "        title=f\"{signal_config['display_name']} - Raw Data for {selected_date}\"\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Store processed data for next cells\n",
    "    values, timestamps_numeric, timestamps = SignalProcessor.prepare_signal_data(df)\n",
    "    print(f\"\\n✅ Data prepared for analysis: {len(values)} points\")\n",
    "else:\n",
    "    print(\"⚠️ No data found for the selected date and signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: PELT Change Point Detection\n",
    "\n",
    "Apply PELT algorithm to detect change points in the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'values' in locals() and len(values) > 0:\n",
    "    # Detect collection periods first\n",
    "    collection_periods = SignalProcessor.detect_collection_periods(df)\n",
    "    print(f\"🔍 Found {len(collection_periods)} collection periods\")\n",
    "    \n",
    "    all_change_points = []\n",
    "    all_segments = []\n",
    "    \n",
    "    # Process each collection period\n",
    "    for i, (start_idx, end_idx) in enumerate(collection_periods):\n",
    "        period_values = values[start_idx:end_idx+1]\n",
    "        period_timestamps = timestamps[start_idx:end_idx+1]\n",
    "        \n",
    "        print(f\"\\n📍 Period {i+1}: {period_timestamps[0]} to {period_timestamps[-1]}\")\n",
    "        print(f\"   Points: {len(period_values)}\")\n",
    "        \n",
    "        # Run PELT on this period\n",
    "        if len(period_values) >= min_segment_size.value * 2:\n",
    "            change_points = SignalProcessor.run_pelt_detection(\n",
    "                period_values,\n",
    "                cost_function=\"l2\",\n",
    "                min_segment_size=min_segment_size.value,\n",
    "                penalty_multiplier=pelt_penalty.value\n",
    "            )\n",
    "            \n",
    "            # Adjust indices to global\n",
    "            global_change_points = [start_idx + cp for cp in change_points]\n",
    "            all_change_points.extend(global_change_points)\n",
    "            \n",
    "            # Create segments\n",
    "            segments = SignalProcessor.create_segments_from_changepoints(\n",
    "                period_values,\n",
    "                period_timestamps,\n",
    "                change_points,\n",
    "                selected_signal\n",
    "            )\n",
    "            all_segments.extend(segments)\n",
    "            \n",
    "            print(f\"   Change points: {len(change_points)}\")\n",
    "            print(f\"   Segments: {len(segments)}\")\n",
    "    \n",
    "    # Visualize PELT results\n",
    "    print(f\"\\n📊 Total change points detected: {len(all_change_points)}\")\n",
    "    print(f\"📊 Total segments created: {len(all_segments)}\")\n",
    "    \n",
    "    # Plot results\n",
    "    fig = SignalVisualizer.plot_pelt_detection(\n",
    "        df,\n",
    "        all_change_points,\n",
    "        all_segments,\n",
    "        signal_config['display_name'],\n",
    "        title=f\"{signal_config['display_name']} - PELT Detection Results\"\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Show segment summary\n",
    "    if all_segments:\n",
    "        segments_df = pd.DataFrame(all_segments)\n",
    "        print(\"\\n📋 Segment Summary:\")\n",
    "        display(segments_df[['state', 'duration_minutes', 'mean_value', 'std_value']]\n",
    "                .groupby('state')\n",
    "                .agg({\n",
    "                    'duration_minutes': ['count', 'sum', 'mean'],\n",
    "                    'mean_value': ['mean', 'std']\n",
    "                })\n",
    "                .round(2))\n",
    "else:\n",
    "    print(\"⚠️ No data available for PELT analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: HDBSCAN Clustering and Smoothing\n",
    "\n",
    "Apply HDBSCAN to cluster and smooth the PELT-detected segments into meaningful events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'all_segments' in locals() and all_segments:\n",
    "    # Prepare features for HDBSCAN\n",
    "    start_of_day = datetime.combine(selected_date, datetime.min.time())\n",
    "    features = SignalProcessor.prepare_hdbscan_features(all_segments, start_of_day)\n",
    "    \n",
    "    print(f\"🔢 Feature matrix shape: {features.shape}\")\n",
    "    print(f\"📊 Features: temporal position, duration, mean value (all normalized)\")\n",
    "    \n",
    "    # Run HDBSCAN\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size.value,\n",
    "        min_samples=2,\n",
    "        metric='manhattan',\n",
    "        cluster_selection_epsilon=epsilon.value,\n",
    "        algorithm='best'\n",
    "    )\n",
    "    \n",
    "    cluster_labels = clusterer.fit_predict(features)\n",
    "    \n",
    "    # Analyze clustering results\n",
    "    n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "    n_noise = list(cluster_labels).count(-1)\n",
    "    \n",
    "    print(f\"\\n🎯 HDBSCAN Results:\")\n",
    "    print(f\"   Clusters found: {n_clusters}\")\n",
    "    print(f\"   Noise points: {n_noise}\")\n",
    "    print(f\"   Clustered points: {len(cluster_labels) - n_noise}\")\n",
    "    \n",
    "    # Visualize clustering\n",
    "    fig = SignalVisualizer.plot_hdbscan_clustering(\n",
    "        all_segments,\n",
    "        features,\n",
    "        cluster_labels,\n",
    "        signal_config['display_name'],\n",
    "        title=f\"{signal_config['display_name']} - HDBSCAN Event Detection\"\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Create events from clusters\n",
    "    events = []\n",
    "    for cluster_id in set(cluster_labels):\n",
    "        if cluster_id == -1:  # Skip noise\n",
    "            continue\n",
    "            \n",
    "        # Get segments in this cluster\n",
    "        cluster_mask = cluster_labels == cluster_id\n",
    "        cluster_segments = [s for i, s in enumerate(all_segments) if cluster_mask[i]]\n",
    "        \n",
    "        if cluster_segments:\n",
    "            # Create event from cluster\n",
    "            event_start = min(s['start_time'] for s in cluster_segments)\n",
    "            event_end = max(s['end_time'] for s in cluster_segments)\n",
    "            \n",
    "            # Determine event type based on dominant state\n",
    "            states = [s['state'] for s in cluster_segments]\n",
    "            dominant_state = max(set(states), key=states.count)\n",
    "            \n",
    "            event = {\n",
    "                'cluster_id': cluster_id,\n",
    "                'start_time': event_start,\n",
    "                'end_time': event_end,\n",
    "                'duration_minutes': (event_end - event_start).total_seconds() / 60,\n",
    "                'dominant_state': dominant_state,\n",
    "                'n_segments': len(cluster_segments),\n",
    "                'mean_value': np.mean([s['mean_value'] for s in cluster_segments])\n",
    "            }\n",
    "            events.append(event)\n",
    "    \n",
    "    # Display events summary\n",
    "    if events:\n",
    "        events_df = pd.DataFrame(events)\n",
    "        print(\"\\n📅 Detected Events:\")\n",
    "        display(events_df.sort_values('start_time'))\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\n📊 Event Statistics:\")\n",
    "        print(f\"   Total events: {len(events)}\")\n",
    "        print(f\"   Total duration: {events_df['duration_minutes'].sum():.1f} minutes\")\n",
    "        print(f\"   Average event duration: {events_df['duration_minutes'].mean():.1f} minutes\")\n",
    "        print(f\"   Dominant states: {events_df['dominant_state'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"⚠️ No segments available for HDBSCAN clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Export\n",
    "\n",
    "Generate a comprehensive summary of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals() and not df.empty:\n",
    "    # Get existing events from database (if any)\n",
    "    db_events = db.get_events_for_date(selected_date)\n",
    "    \n",
    "    # Create combined visualization\n",
    "    fig = SignalVisualizer.plot_combined_analysis(\n",
    "        df,\n",
    "        all_segments if 'all_segments' in locals() else [],\n",
    "        cluster_labels if 'cluster_labels' in locals() else np.array([]),\n",
    "        db_events if not db_events.empty else None,\n",
    "        signal_config['display_name']\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    if 'all_segments' in locals() and 'cluster_labels' in locals():\n",
    "        summary_stats = SignalVisualizer.create_summary_stats(\n",
    "            df,\n",
    "            all_segments,\n",
    "            cluster_labels\n",
    "        )\n",
    "        print(\"\\n📊 Analysis Summary:\")\n",
    "        display(summary_stats)\n",
    "    \n",
    "    print(\"\\n✅ Analysis complete!\")\n",
    "else:\n",
    "    print(\"⚠️ No data available for summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "db.close()\n",
    "print(\"🔒 Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
